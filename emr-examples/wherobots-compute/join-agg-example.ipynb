{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98077135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Import local library\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "## Import GeoPandas\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Import PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, expr, broadcast, udf, lit, struct\n",
    "\n",
    "## Import Apache Sedona\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "from sedona.core.formatMapper.shapefileParser import ShapefileReader\n",
    "from sedona.utils.adapter import Adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed79cdd1-b781-4ccf-a3a9-7c1415cfadac",
   "metadata": {},
   "source": [
    "# Define spark session if not defined yet\n",
    "No need to define spark if run in an external cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ca752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName('appName'). \\\n",
    "    master('local[*]'). \\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName). \\\n",
    "    config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName). \\\n",
    "    config(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\"). \\\n",
    "    config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1271a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SedonaRegistrator.registerAll(spark)\n",
    "sc = spark.sparkContext\n",
    "sc.setSystemProperty(\"sedona.global.charset\", \"utf8\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\")\n",
    "\n",
    "def delete_path(sc, path):\n",
    "    fs = (sc._jvm.org\n",
    "          .apache.hadoop\n",
    "          .fs.FileSystem\n",
    "          .get(sc._jsc.hadoopConfiguration())\n",
    "          )\n",
    "    fs.delete(sc._jvm.org.apache.hadoop.fs.Path(path), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bdebb5",
   "metadata": {},
   "source": [
    "# Use the prefix in all your EMR path\n",
    "\n",
    "If you use EMR, EMR requires that all paths must be relative. You can use the variable below as the prefix for all paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723f00c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PATH_PREFIX= str(Path.home()) + '/' if os.environ.get('ENV_WB', 'false') == 'true' else ''\n",
    "\n",
    "print(PATH_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7de7d9",
   "metadata": {},
   "source": [
    "# Load taxi pickup records to Sedona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a55290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxidf = spark.read.format('csv').option(\"header\",\"true\").option(\"delimiter\", \",\").load(\"s3a://wherobots-examples/data/nyc-taxi-data.csv\")\n",
    "taxidf = taxidf.selectExpr('ST_Point(CAST(Start_Lon AS Decimal(24,20)), CAST(Start_Lat AS Decimal(24,20))) AS pickup', 'Trip_Pickup_DateTime', 'Payment_Type', 'Fare_Amt')\n",
    "taxidf = taxidf.filter(col(\"pickup\").isNotNull())\n",
    "taxidf.show()\n",
    "taxidf.createOrReplaceTempView('taxiDf')\n",
    "taxiRdd = Adapter.toSpatialRdd(taxidf, \"pickup\")\n",
    "import shutil\n",
    "shutil.rmtree(PATH_PREFIX + \"taxi-pickup.geojson\", ignore_errors=True)\n",
    "delete_path(sc, PATH_PREFIX + \"taxi-pickup.geojson\")\n",
    "taxiRdd.saveAsGeoJSON(PATH_PREFIX + \"taxi-pickup.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528e9e15",
   "metadata": {},
   "source": [
    "# Load Zones to Sedona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929dae44",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "zoneDf = spark.read.format('csv').option(\"delimiter\", \",\").load(\"s3a://wherobots-examples/data/TIGER2018_ZCTA5.csv\")\n",
    "zoneDf = zoneDf.selectExpr('ST_GeomFromWKT(_c0) as zone', '_c1 as zipcode')\n",
    "zoneDf.show()\n",
    "zoneDf.createOrReplaceTempView('zoneDf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd5765",
   "metadata": {},
   "source": [
    "# Visualize Sedona Dataframes on maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5e7e19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zoneGpd = gpd.GeoDataFrame(zoneDf.toPandas(), geometry=\"zone\")\n",
    "taxiGpd = gpd.GeoDataFrame(taxidf.toPandas(), geometry=\"pickup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b638dd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "zone = zoneGpd.plot(color='yellow', edgecolor='black', zorder=1)\n",
    "zone.set_xlabel('Longitude (degrees)')\n",
    "zone.set_ylabel('Latitude (degrees)')\n",
    "\n",
    "# Local view\n",
    "zone.set_xlim(-74.1, -73.8)\n",
    "zone.set_ylim(40.65, 40.9)\n",
    "\n",
    "taxi = taxiGpd.plot(ax=zone, alpha=0.01, color='red', zorder=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e781c-3e85-4d1c-8009-499470eedf92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplot plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845062e9",
   "metadata": {},
   "source": [
    "# Find taxis in each zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac2857",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxiVsZone = spark.sql('SELECT zone, zipcode, pickup, Fare_Amt FROM zoneDf, taxiDf WHERE ST_Contains(zone, pickup)')\n",
    "taxiVsZone.show()\n",
    "taxiVsZone.createOrReplaceTempView(\"taxiVsZone\")\n",
    "taxiVsZone = taxiVsZone.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264a615d",
   "metadata": {},
   "source": [
    "# Count taxis per zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a93a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxiPerZone = spark.sql(\"SELECT zone, zipcode, count(*) as count, avg(Fare_Amt) as avg_fare FROM taxiVsZone c GROUP BY zone, zipcode\")\n",
    "taxiPerZone.show()\n",
    "taxiPerZoneRdd = Adapter.toSpatialRdd(taxiPerZone, \"zone\")\n",
    "import shutil\n",
    "shutil.rmtree(PATH_PREFIX + \"taxi-per-zone.geojson\", ignore_errors=True)\n",
    "delete_path(sc, PATH_PREFIX + \"taxi-per-zone.geojson\")\n",
    "taxiPerZoneRdd.saveAsGeoJSON(PATH_PREFIX + \"taxi-per-zone.geojson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8634cc82",
   "metadata": {},
   "source": [
    "# Visualize the result on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61e292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(taxiPerZone.toPandas(), geometry=\"zone\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "result = gdf.plot(\n",
    "    column=\"count\",\n",
    "    legend=True,\n",
    "    cmap='OrRd',\n",
    "    cax=cax,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Local view\n",
    "result.set_xlim(-74.1, -73.8)\n",
    "result.set_ylim(40.65, 40.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c6a95-c507-4e92-905b-e98593543147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplot plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

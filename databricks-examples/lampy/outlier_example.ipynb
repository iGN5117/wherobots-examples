{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eaf5d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:18:53.768863Z",
     "iopub.status.busy": "2023-02-11T08:18:53.768548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1808685dab4610830fd2eba02fe194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: The Spark session does not have enough YARN resources to start. \n"
     ]
    }
   ],
   "source": [
    "# Import local libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Import GeoPandas\n",
    "import geopandas as gpd\n",
    "\n",
    "# Import PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, DoubleType, FloatType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "# Import Apache Sedona\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.core.formatMapper.shapefileParser import ShapefileReader\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "from sedona.utils.adapter import Adapter as adp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd00c43",
   "metadata": {},
   "source": [
    "## Define spark session if not defined yet\n",
    "No need to define spark if run in an external cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d9f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    appName('appName'). \\\n",
    "    master('local[*]'). \\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName). \\\n",
    "    config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName). \\\n",
    "    config(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\"). \\\n",
    "    config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "SedonaRegistrator.registerAll(spark)\n",
    "sc = spark.sparkContext\n",
    "sc.setSystemProperty(\"sedona.global.charset\", \"utf8\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa5127",
   "metadata": {},
   "source": [
    "# Use the prefix in all your DBFS path\n",
    "\n",
    "If you use DBFS, Databricks requires that all paths must be absolute. You can use the variable below as the prefix for all paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fdc149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PATH_PREFIX= str(Path.home()) + '/' if os.environ.get('ENV_WB', 'false') == 'true' else '/'\n",
    "\n",
    "print(PATH_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a562ad1",
   "metadata": {},
   "source": [
    "## Load Taxi Pick Up Data to Sedona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_rdd = ShapefileReader.readToGeometryRDD(sc, \"s3a://wherobots-examples/data/pickup_data/shape_file\")\n",
    "zones_df = adp.toDf(zones_rdd, spark)\n",
    "zones_df = zones_df.drop(\"_id\")\n",
    "zones_df = zones_df.rdd.zipWithIndex().toDF()\n",
    "zones_df = zones_df.select(col(\"_1.*\"), col(\"_2\").alias('ids'))\n",
    "zones_df = zones_df.withColumn(\"pickup_count\", zones_df.pickup_cou.cast(IntegerType())).drop(\"pickup_cou\")\n",
    "zones_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db815f",
   "metadata": {},
   "source": [
    "## Outlier Detection\n",
    "Get box maps statistics of the Sedona DataFrame for the attribute pickup_count. The Sedona DataFrame will be returned with a new attribute named box_statistics_class which defines the class of each record. Outlier is one of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fa413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lampy import Outliers\n",
    "from lampy import SparkRegistration\n",
    "\n",
    "SparkRegistration.set_spark_session(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_df = Outliers.get_box_map_statistics(zones_df, \"pickup_count\")\n",
    "outlier_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef983e4",
   "metadata": {},
   "source": [
    "## Visualize the Class of each Record\n",
    "Each class is defined by a color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e119082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_gdf = gpd.GeoDataFrame(outlier_df.toPandas(), geometry = \"geometry\", crs = \"EPSG:4326\")\n",
    "ax = outlier_gdf.plot(column='box_statistics_class', categorical=True, aspect = 'equal', legend=True, legend_kwds={'loc': 'center left', 'bbox_to_anchor':(1,0.5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0ab345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
